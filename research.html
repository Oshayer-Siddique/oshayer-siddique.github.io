<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research - Oshayer Siddique</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Times New Roman', serif; line-height: 1.6; color: #333; background-color: #ffffff; }
        header { background-color: #ffffff; border-bottom: 2px solid #e5e5e5; position: fixed; width: 100%; top: 0; z-index: 100; }
        .header-container { max-width: 1200px; margin: 0 auto; display: flex; justify-content: space-between; align-items: center; padding: 0 40px; height: 80px; }
        .logo { font-size: 24px; font-weight: bold; color: #2c3e50; text-decoration: none; letter-spacing: 1px; }
        .nav { display: flex; list-style: none; }
        .nav li { margin-left: 40px; }
        .nav a { text-decoration: none; color: #333; font-size: 16px; font-weight: 500; transition: color 0.3s ease; padding-bottom: 5px; }
        .nav a:hover { color: #2c3e50; }
        .nav a.active { font-weight: bold; color: #2c3e50; border-bottom: 2px solid #2c3e50; }
        main { margin-top: 80px; }
        .container { max-width: 1200px; margin: 0 auto; padding: 0 40px; }
        section { padding: 80px 0; }
        h2 { font-size: 36px; color: #2c3e50; margin-bottom: 50px; text-align: center; font-weight: normal; }
        h3 { font-size: 24px; color: #2c3e50; margin-bottom: 20px; font-weight: normal; }
        .research-overview { background-color: #f8f9fa; padding: 40px; border-radius: 8px; margin-bottom: 60px; }
        .research-focus { font-size: 18px; line-height: 1.7; color: #2c3e50; text-align: center; font-style: italic; }
        .research-item { margin-bottom: 50px; padding: 30px; border-left: 4px solid #3498db; background-color: #fafbfc; }
        .paper-title { font-size: 24px; font-weight: bold; color: #2c3e50; margin-bottom: 15px; line-height: 1.3; }
        .item-details { color: #666; font-style: italic; margin-bottom: 20px; font-size: 16px; }
        .item-abstract { font-size: 16px; line-height: 1.7; margin-bottom: 25px; text-align: justify; }
        .item-metrics { display: flex; gap: 20px; margin-bottom: 20px; flex-wrap: wrap; }
        .metric { background-color: #e8f4f8; padding: 8px 15px; border-radius: 20px; font-size: 14px; color: #2c3e50; font-weight: 600; }
        .item-links { display: flex; gap: 15px; flex-wrap: wrap; }
        .item-link a { background-color: #3498db; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: 600; transition: background-color 0.3s ease; display: inline-block; }
        .item-link a:hover { background-color: #2980b9; }
        .item-link.secondary a { background-color: #95a5a6; }
        .item-link.secondary a:hover { background-color: #7f8c8d; }
        .research-areas { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 30px; margin-bottom: 50px; }
        .research-area { background-color: #ffffff; padding: 25px; border: 1px solid #e5e5e5; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
        .area-title { font-size: 20px; font-weight: bold; color: #2c3e50; margin-bottom: 15px; }
        .area-description { font-size: 15px; line-height: 1.6; color: #555; }
        .impact-section { background-color: #f8f9fa; padding: 40px; border-radius: 8px; margin-bottom: 50px; }
        .impact-stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-top: 30px; }
        .stat-item { text-align: center; padding: 20px; background-color: white; border-radius: 8px; }
        .stat-number { font-size: 32px; font-weight: bold; color: #3498db; display: block; }
        .stat-label { font-size: 14px; color: #666; margin-top: 5px; }
        footer { background-color: #2c3e50; color: white; text-align: center; padding: 40px 0; }
        @media (max-width: 768px) {
            .header-container, .container { padding: 0 20px; }
            .nav { display: none; }
            h2 { font-size: 28px; }
            .paper-title { font-size: 20px; }
            .research-areas { grid-template-columns: 1fr; }
            .impact-stats { grid-template-columns: repeat(2, 1fr); }
            .item-metrics, .item-links { flex-direction: column; }
        }
    </style>
</head>
<body>
    <header>
        <div class="header-container">
            <a href="index.html" class="logo">Oshayer Siddique</a>
            <nav>
                <ul class="nav">
                    <li><a href="index.html">Home</a></li>
                    <li><a href="about.html">About</a></li>
                    <li><a href="experience.html">Experience</a></li>
                    <li><a href="research.html" class="active">Research</a></li>
                    <li><a href="publications.html">Publications</a></li>
                    <li><a href="contact.html">Contact</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <section id="research">
            <div class="container">
                <h2>Research Portfolio</h2>
                
                <div class="research-overview">
                    <p class="research-focus">
                        My research explores the fundamental mechanisms of reasoning in Large Language Models, with a particular focus on scientific problem-solving and the development of robust evaluation frameworks for AI reasoning capabilities.
                    </p>
                </div>

                <div class="impact-section">
                    <h3>Research Impact</h3>
                    <div class="impact-stats">
                        <div class="stat-item">
                            <span class="stat-number">19,609</span>
                            <div class="stat-label">Physics Problems in Dataset</div>
                        </div>
                        <div class="stat-item">
                            <span class="stat-number">1</span>
                            <div class="stat-label">ACL Findings Publication</div>
                        </div>
                        <div class="stat-item">
                            <span class="stat-number">World's</span>
                            <div class="stat-label">Largest Physics Reasoning Dataset</div>
                        </div>
                        <div class="stat-item">
                            <span class="stat-number">Open</span>
                            <div class="stat-label">Source Contributions</div>
                        </div>
                    </div>
                </div>

                <h3>Published Research</h3>
                
                <div class="research-item">
                    <div class="paper-title">PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems</div>
                    <div class="item-details">
                        <strong>Authors:</strong> Oshayer Siddique et al.<br>
                        <strong>Venue:</strong> ACL Findings 2025 (The Association for Computational Linguistics)<br>
                        <strong>Publication Date:</strong> December 2025
                    </div>
                    <div class="item-metrics">
                        <span class="metric">Novel Inference Techniques</span>
                        <span class="metric">Physics Reasoning</span>
                        <span class="metric">LLM Evaluation</span>
                        <span class="metric">Benchmark Dataset</span>
                    </div>
                    <div class="item-abstract">
                        This groundbreaking research introduces novel inference-time techniques specifically designed to enhance Large Language Models' ability to reason through complex physics problems. <strong>The study presents the PhysicsEval dataset—the world's largest physics reasoning benchmark with 19,609 carefully curated problems</strong>—and demonstrates significant improvements in LLM performance without modifying underlying model architectures. The work provides critical insights into current model limitations and establishes a practical framework for building more robust AI systems capable of scientific reasoning. Our methodology bridges the gap between pattern recognition and genuine logical reasoning, offering a new paradigm for evaluating and improving AI performance in scientific domains.
                    </div>
                    <div class="item-links">
                        <div class="item-link">
                            <a href="https://arxiv.org/abs/2508.00079" target="_blank">View Paper (arXiv)</a>
                        </div>
                        <div class="item-link secondary">
                            <a href="https://www.researchgate.net/publication/394263077_PhysicsEval_Inference-Time_Techniques_to_Improve_the_Reasoning_Proficiency_of_Large_Language_Models_on_Physics_Problems" target="_blank">ResearchGate</a>
                        </div>
                    </div>
                </div>

                <h3>Research Resources & Contributions</h3>
                
                <div class="research-item">
                    <div class="paper-title">PhysicsEval Dataset: The World's Largest Physics Reasoning Benchmark</div>
                    <div class="item-details">
                        <strong>Repository:</strong> Hugging Face Datasets<br>
                        <strong>Size:</strong> 19,609 physics problems with solutions<br>
                        <strong>Availability:</strong> Open source, publicly accessible
                    </div>
                    <div class="item-metrics">
                        <span class="metric">19,609 Problems</span>
                        <span class="metric">Multiple Physics Domains</span>
                        <span class="metric">Verified Solutions</span>
                        <span class="metric">Community Resource</span>
                    </div>
                    <div class="item-abstract">
                        The PhysicsEval dataset represents the most comprehensive physics reasoning benchmark ever created for AI evaluation. Sourced from diverse physics textbooks and verified through educational forums, this dataset challenges models to apply fundamental principles and logical reasoning rather than relying on pattern matching. <strong>The dataset spans multiple physics domains including mechanics, thermodynamics, electromagnetism, and quantum physics</strong>, providing researchers with an unprecedented tool for evaluating and advancing AI reasoning capabilities. Each problem includes detailed solutions and step-by-step reasoning paths, making it invaluable for both evaluation and training purposes.
                    </div>
                    <div class="item-links">
                        <div class="item-link">
                            <a href="https://huggingface.co/datasets/IUTVanguard/PhysicsEval" target="_blank">Access Dataset</a>
                        </div>
                        <!-- <div class="item-link secondary">
                            <a href="#" target="_blank">📋 Documentation</a>
                        </div> -->
                    </div>
                </div>

                <h3>Current Research Direction</h3>
                
                <div class="research-item">
                    <div class="paper-title">Investigating the Core Mechanisms of LLM Reasoning</div>
                    <div class="item-details">
                        <strong>Status:</strong> Ongoing Research<br>
                        <strong>Focus:</strong> Fundamental reasoning components in Large Language Models<br>
                        <strong>Expected Outcome:</strong> Novel insights into AI reasoning architecture
                    </div>
                    <div class="item-metrics">
                        <span class="metric">Reasoning Analysis</span>
                        <span class="metric">Model Interpretability</span>
                        <span class="metric">Cognitive Architecture</span>
                        <span class="metric">AI Transparency</span>
                    </div>
                    <div class="item-abstract">
                        My current research addresses a fundamental question in artificial intelligence: <strong>What constitutes the core of reasoning in Large Language Models?</strong> This investigation aims to deconstruct and analyze the specific components and mechanisms within LLMs that enable their logical and problem-solving capabilities. By understanding these underlying processes, we can develop more transparent, reliable, and effective AI systems. The research involves systematic analysis of attention patterns, layer-wise reasoning development, and the emergence of logical structures during training. This work promises to provide unprecedented insights into how artificial intelligence systems develop and apply reasoning abilities, potentially leading to breakthrough advances in interpretable AI.
                    </div>
                    <div class="item-links">
                    </div>
                </div>

                <h3>Research Areas</h3>
                
                <div class="research-areas">
                    <div class="research-area">
                        <div class="area-title">Physics-Informed AI</div>
                        <div class="area-description">Developing AI systems that understand and apply fundamental physics principles, bridging the gap between symbolic reasoning and neural computation.</div>
                    </div>
                    <div class="research-area">
                        <div class="area-title">LLM Reasoning Mechanisms</div>
                        <div class="area-description">Investigating the internal processes that enable reasoning in large language models, focusing on interpretability and cognitive architectures.</div>
                    </div>
                    <div class="research-area">
                        <div class="area-title">Scientific Problem Solving</div>
                        <div class="area-description">Creating robust evaluation frameworks and methodologies for assessing AI performance on complex scientific and mathematical problems.</div>
                    </div>
                    <div class="research-area">
                        <div class="area-title">Benchmark Development</div>
                        <div class="area-description">Designing comprehensive datasets and evaluation metrics that push the boundaries of current AI capabilities and reveal fundamental limitations.</div>
                    </div>
                </div>

            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Oshayer Siddique. All rights reserved.</p>
        </div>
    </footer>

    <script>
        window.addEventListener('scroll', function() {
            const header = document.querySelector('header');
            if (window.scrollY > 50) {
                header.style.boxShadow = '0 2px 5px rgba(0,0,0,0.1)';
            } else {
                header.style.boxShadow = 'none';
            }
        });
    </script>
</body>
</html>